{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "6e3f6bc3",
            "metadata": {},
            "source": [
                "# RAG Assignment - Google Colab Version\n",
                "\n",
                "## Problem Statement\n",
                "This notebook implements a Retrieval-Augmented Generation (RAG) pipeline to answer questions based on a provided company policy document (`knowledge_base.txt`).\n",
                "\n",
                "## 1. Setup and Installation\n",
                "Since this is running in Colab, we first need to install the required libraries."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "94ce1c39",
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install -q langchain langchain-community langchain-huggingface faiss-cpu sentence-transformers"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Prepare Dataset\n",
                "We create the `knowledge_base.txt` file directly in this environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "knowledge_base_content = \"\"\"Remote Work Policy - Acme Corp\n",
                "Effective Date: January 1, 2024\n",
                "\n",
                "1. Purpose\n",
                "The purpose of this Remote Work Policy is to outline the guidelines and expectations for employees working remotely. Acme Corp recognizes the benefits of remote work in promoting work-life balance and productivity.\n",
                "\n",
                "2. Eligibility\n",
                "Full-time employees who have completed their probationary period are eligible to apply for remote work. Roles that require physical presence (e.g., hardware maintenance, front-desk reception) are not eligible.\n",
                "\n",
                "3. Work Hours & Availability\n",
                "Remote employees must be available during core business hours (10:00 AM - 4:00 PM EST). Employees are expected to maintain the same level of productivity and responsiveness as they would in the office.\n",
                "\n",
                "4. Equipment & Security\n",
                "Acme Corp will provide a company laptop and necessary software. Employees must ensure their home Wi-Fi network is secure and password-protected. Use of public Wi-Fi for handling sensitive company data is strictly prohibited unless a VPN is used.\n",
                "\n",
                "5. Communication\n",
                "Employees should use Slack for asynchronous communication and Zoom for meetings. Weekly check-ins with managers are mandatory.\n",
                "\n",
                "6. Expense Reimbursement\n",
                "Acme Corp will reimburse up to $50/month for internet expenses. Home office furniture or electricity costs are not reimbursable.\n",
                "\n",
                "7. Termination of Remote Work\n",
                "Acme Corp reserves the right to terminate remote work agreements at any time if performance standards are not met or business needs change.\"\"\"\n",
                "\n",
                "with open('knowledge_base.txt', 'w') as f:\n",
                "    f.write(knowledge_base_content)\n",
                "\n",
                "print(\"Created 'knowledge_base.txt' successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. RAG Pipeline Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from typing import List\n",
                "from langchain_community.document_loaders import TextLoader\n",
                "try:\n",
                "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
                "except ImportError:\n",
                "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "from langchain_huggingface import HuggingFaceEmbeddings\n",
                "from langchain_community.vectorstores import FAISS\n",
                "\n",
                "# 1. Load Data\n",
                "loader = TextLoader('knowledge_base.txt')\n",
                "documents = loader.load()\n",
                "print(f\"Loaded {len(documents)} document(s).\")\n",
                "\n",
                "# 2. Chunking\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=500,\n",
                "    chunk_overlap=50,\n",
                "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
                ")\n",
                "chunks = text_splitter.split_documents(documents)\n",
                "print(f\"Split into {len(chunks)} chunks.\")\n",
                "\n",
                "# 3. Embeddings (Using langchain-huggingface)\n",
                "print(\"Initializing Embedding Model...\")\n",
                "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
                "\n",
                "# 4. Vector Store\n",
                "print(\"Creating Vector Store...\")\n",
                "vector_store = FAISS.from_documents(chunks, embedding_model)\n",
                "print(\"Vector store created successfully.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Retrieval & Generation (Mock LLM)\n",
                "Simulating the LLM response generation."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class MockLLM:\n",
                "    def __init__(self, vector_store):\n",
                "        self.vector_store = vector_store\n",
                "\n",
                "    def answer_question(self, query):\n",
                "        # Retrieve\n",
                "        docs = self.vector_store.similarity_search(query, k=2)\n",
                "        \n",
                "        # Mock Generation\n",
                "        response = f\"\"\"\n",
                "        [Generated Answer]\n",
                "        Based on the policy:\n",
                "        - Found in: {docs[0].page_content[:100]}...\n",
                "        (This is a mock, replace with OpenAI for real generation)\n",
                "        \"\"\"\n",
                "        return response, docs\n",
                "\n",
                "rag_system = MockLLM(vector_store)\n",
                "\n",
                "test_queries = [\n",
                "    \"What is the eligibility for remote work?\",\n",
                "    \"Does the company pay for internet?\",\n",
                "    \"What are the core work hours?\"\n",
                "]\n",
                "\n",
                "print(\"--- Test Results ---\")\n",
                "for query in test_queries:\n",
                "    print(f\"\\nQuery: {query}\")\n",
                "    answer, source_docs = rag_system.answer_question(query)\n",
                "    print(f\"Answer: {answer}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
